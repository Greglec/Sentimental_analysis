{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\grego\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import random\n",
    "#from nltk.corpus import movie_reviews\n",
    "from nltk.classify.scikitlearn import SklearnClassifier #for scilearn classifier\n",
    "import pickle\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC,NuSVC\n",
    "\n",
    "from nltk.classify import ClassifierI #so we can inherate from the nltk classifier class\n",
    "from statistics import mode #for the classifier vote system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScoreClassifier(ClassifierI): #we pass a list of classifiers through this class\n",
    "    def __init__(self, *classifiers):#init method to run any methods\n",
    "        self._classifiers = classifiers #classifier list will be whatever list of classifiers passed \n",
    "        \n",
    "    def classify(self, features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "        return mode(votes)#returns number of votes\n",
    "    \n",
    "    def confidence(self,features):\n",
    "        votes=[]\n",
    "        for c in self._classifiers:\n",
    "            v=c.classify(features)\n",
    "            votes.append(v)\n",
    "        choice_votes = votes.count(mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#building training sets\n",
    "\n",
    "pos_review = open(\"positive_review.txt\",\"r\").read()\n",
    "neg_review = open(\"negative_review.txt\",\"r\").read()\n",
    "\n",
    "all_words = []\n",
    "documents = []\n",
    "\n",
    "#J is adjectiv, R is adverb and v is verb\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "for r in pos_review.split('\\n'):\n",
    "    documents.append((r,\"pos\"))\n",
    "    words = word_tokenize(r)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "        \n",
    "for r in neg_review.split('\\n'):\n",
    "    documents.append((r,\"neg\"))\n",
    "    words = word_tokenize(r)\n",
    "    pos = nltk.pos_tag(words)\n",
    "    for w in pos:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "#saving documents and all_words in pickle\n",
    "save_doc=open(\"documents.pickle\",\"wb\")\n",
    "pickle.dump(documents,save_doc)\n",
    "save_doc.close\n",
    "\n",
    "save_words=open(\"all_words.pickle\",\"wb\")\n",
    "pickle.dump(all_words,save_words)\n",
    "save_words.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('good', 369), ('more', 331), ('little', 265), ('funny', 245), ('much', 234), ('bad', 234), ('best', 208), ('new', 206), ('own', 185), ('many', 183), ('most', 167), ('other', 167), ('great', 160), ('big', 156), ('few', 139)]\n"
     ]
    }
   ],
   "source": [
    "#transforming all words in nltk freq distribution\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "\n",
    "#top 15 most common words\n",
    "print(all_words.most_common(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "print(all_words[\"bad\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function BufferedWriter.close>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#features : 5000 words for training \n",
    "word_features = list(all_words.keys())[:5000]\n",
    "\n",
    "#saving in pickle\n",
    "save_features=open(\"word_features.pickle\",\"wb\")\n",
    "pickle.dump(word_features,save_features)\n",
    "save_features.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert words in dictionnary of 5000 words with category true (neg) or false (pos)\n",
    "featuresets = [(find_features(rev), category) for (rev,category) in documents ]\n",
    "\n",
    "save_featuresets=open(\"featuresets.pickle\",\"wb\")\n",
    "pickle.dump(featuresets,save_featuresets)\n",
    "save_featuresets.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(featuresets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = featuresets[:10000]\n",
    "D_test = featuresets[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_classifier = nltk.NaiveBayesClassifier.train(D_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              engrossing = True              pos : neg    =     21.0 : 1.0\n",
      "                 generic = True              neg : pos    =     16.4 : 1.0\n",
      "                mediocre = True              neg : pos    =     16.4 : 1.0\n",
      "                 routine = True              neg : pos    =     15.0 : 1.0\n",
      "                    dull = True              neg : pos    =     14.8 : 1.0\n",
      "               inventive = True              pos : neg    =     14.3 : 1.0\n",
      "                    flat = True              neg : pos    =     14.2 : 1.0\n",
      "                  boring = True              neg : pos    =     13.9 : 1.0\n",
      "              refreshing = True              pos : neg    =     13.6 : 1.0\n",
      "                    warm = True              pos : neg    =     12.6 : 1.0\n",
      "                powerful = True              pos : neg    =     12.4 : 1.0\n",
      "                   stale = True              neg : pos    =     11.7 : 1.0\n",
      "                mindless = True              neg : pos    =     11.7 : 1.0\n",
      "               realistic = True              pos : neg    =     11.6 : 1.0\n",
      "             mesmerizing = True              pos : neg    =     11.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "#15 most informative features of our dictionnary:\n",
    "NB_classifier.show_most_informative_features(15)\n",
    "#engrossing appears 20.3 times more in a neg review than a pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Algo accuracy percent: 73.90648567119156\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Algo accuracy percent:\", (nltk.classify.accuracy(NB_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving classifier so that we dont have to re train it\n",
    "save_classifier=open(\"NB_classifier.pickle\",\"wb\")\n",
    "pickle.dump(NB_classifier,save_classifier)\n",
    "save_classifier.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial accuracy percent: 70.58823529411765\n"
     ]
    }
   ],
   "source": [
    "#Multinomial\n",
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"MNB_classifier.pickle\",\"wb\")\n",
    "pickle.dump(MNB_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"Multinomial accuracy percent:\", (nltk.classify.accuracy(MNB_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB accuracy percent: 74.81146304675717\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"BernoulliNB_classifier.pickle\",\"wb\")\n",
    "pickle.dump(BernoulliNB_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"BernoulliNB accuracy percent:\", (nltk.classify.accuracy(BernoulliNB_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy percent: 71.94570135746606\n"
     ]
    }
   ],
   "source": [
    "#Logistic reg\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"LogisticRegression_classifier.pickle\",\"wb\")\n",
    "pickle.dump(LogisticRegression_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"LogisticRegression accuracy percent:\", (nltk.classify.accuracy(LogisticRegression_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StochasticGradient_classifier accuracy percent: 72.54901960784314\n"
     ]
    }
   ],
   "source": [
    "#Stochastic gradient classifier\n",
    "StochasticGradient_classifier = SklearnClassifier(SGDClassifier())\n",
    "StochasticGradient_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"StochasticGradient_classifier.pickle\",\"wb\")\n",
    "pickle.dump(StochasticGradient_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"StochasticGradient_classifier accuracy percent:\", (nltk.classify.accuracy(StochasticGradient_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\grego\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC accuracy percent: 49.17043740573152\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = SklearnClassifier(SVC())\n",
    "SVC_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"SVC_classifier.pickle\",\"wb\")\n",
    "pickle.dump(SVC_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"SVC accuracy percent:\", (nltk.classify.accuracy(SVC_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC accuracy percent: 70.2865761689291\n"
     ]
    }
   ],
   "source": [
    "#Linear SVM\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"LinearSVC_classifier.pickle\",\"wb\")\n",
    "pickle.dump(LinearSVC_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"Linear SVC accuracy percent:\", (nltk.classify.accuracy(LinearSVC_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu SVC accuracy percent: 72.2473604826546\n"
     ]
    }
   ],
   "source": [
    "#with nu we can customize the nb of support vectors used\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(D_train)\n",
    "\n",
    "save_classifier=open(\"NuSVC_classifier.pickle\",\"wb\")\n",
    "pickle.dump(NuSVC_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"Nu SVC accuracy percent:\", (nltk.classify.accuracy(NuSVC_classifier,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "voted accuracy percent: 73.00150829562594\n"
     ]
    }
   ],
   "source": [
    "voted_classifier = ScoreClassifier(NB_classifier, MNB_classifier,BernoulliNB_classifier, LogisticRegression_classifier,StochasticGradient_classifier,SVC_classifier,NuSVC_classifier)\n",
    "\n",
    "save_classifier=open(\"voted_classifier.pickle\",\"wb\")\n",
    "pickle.dump(voted_classifier,save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print(\"voted accuracy percent:\", (nltk.classify.accuracy(voted_classifier ,D_test))*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: pos Confidence %: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[0][0]),\"Confidence %:\",voted_classifier.confidence(D_test[0][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: pos Confidence %: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[1][0]),\"Confidence %:\",voted_classifier.confidence(D_test[1][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: pos Confidence %: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[2][0]),\"Confidence %:\",voted_classifier.confidence(D_test[2][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: neg Confidence %: 85.71428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[3][0]),\"Confidence %:\",voted_classifier.confidence(D_test[3][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: pos Confidence %: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[4][0]),\"Confidence %:\",voted_classifier.confidence(D_test[4][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: neg Confidence %: 85.71428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification:\", voted_classifier.classify(D_test[5][0]),\"Confidence %:\",voted_classifier.confidence(D_test[5][0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
